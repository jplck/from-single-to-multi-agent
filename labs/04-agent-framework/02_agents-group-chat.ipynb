{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings\n",
    ")\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.agents import AgentGroupChat, ChatCompletionAgent\n",
    "from semantic_kernel.functions import KernelFunctionFromPrompt\n",
    "from semantic_kernel.contents import ChatHistoryTruncationReducer\n",
    "from semantic_kernel.agents.strategies import (\n",
    "    KernelFunctionSelectionStrategy,\n",
    "    KernelFunctionTerminationStrategy,\n",
    ")\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_kernel():\n",
    "    \"\"\"Create a kernel with Azure OpenAI service\"\"\"\n",
    "    kernel = Kernel()\n",
    "    \n",
    "    # Add Azure OpenAI service\n",
    "    kernel.add_service(\n",
    "        AzureChatCompletion(\n",
    "            service_id=\"azure_openai\",\n",
    "            deployment_name=os.environ.get(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "            api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "            endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    return kernel\n",
    "\n",
    "# Let's create our kernel\n",
    "kernel = create_kernel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "REVIEWER_NAME = \"Reviewer\"\n",
    "WRITER_NAME = \"Writer\"\n",
    "\n",
    "execution_settings = AzureChatPromptExecutionSettings(\n",
    "    service_id=\"azure_openai\",\n",
    "    max_tokens=1000,\n",
    ")\n",
    "\n",
    "reviewer = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=REVIEWER_NAME,\n",
    "    instructions=\"\"\"Your responsibility is to review and identify how to improve user provided content.\n",
    "If the user has provided input or direction for content already provided, specify how to address this input.\n",
    "Never directly perform the correction or provide an example.\n",
    "Once the content has been updated in a subsequent response, review it again until it is satisfactory.\n",
    "\n",
    "RULES:\n",
    "- Only identify suggestions that are specific and actionable.\n",
    "- Verify previous suggestions have been addressed.\n",
    "- Never repeat previous suggestions.\",\n",
    ")\n",
    "\"\"\"\n",
    ")\n",
    "\n",
    "copywriter = ChatCompletionAgent(\n",
    "    kernel=kernel,\n",
    "    name=WRITER_NAME,\n",
    "    instructions=\"\"\"\n",
    "Your sole responsibility is to rewrite content according to review suggestions.\n",
    "- Always apply all review directions.\n",
    "- Always revise the content in its entirety without explanation.\n",
    "- Never address the user.  \n",
    "    \"\"\",\n",
    "    arguments=KernelArguments(settings=execution_settings)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AgentGroupChat(agents=[reviewer, copywriter])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"selection\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the provided RESPONSE and choose the next participant.\n",
    "State only the name of the chosen participant without explanation.\n",
    "Never choose the participant named in the RESPONSE.\n",
    "\n",
    "Choose only from these participants:\n",
    "- {REVIEWER_NAME}\n",
    "- {WRITER_NAME}\n",
    "\n",
    "Rules:\n",
    "- If RESPONSE is user input, it is {REVIEWER_NAME}'s turn.\n",
    "- If RESPONSE is by {REVIEWER_NAME}, it is {WRITER_NAME}'s turn.\n",
    "- If RESPONSE is by {WRITER_NAME}, it is {REVIEWER_NAME}'s turn.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "termination_keyword = \"yes\"\n",
    "\n",
    "termination_function = KernelFunctionFromPrompt(\n",
    "    function_name=\"termination\", \n",
    "    prompt=f\"\"\"\n",
    "Examine the RESPONSE and determine whether the content has been deemed satisfactory.\n",
    "If the content is satisfactory, respond with a single word without explanation: {termination_keyword}.\n",
    "If specific suggestions are being provided, it is not satisfactory.\n",
    "If no correction is suggested, it is satisfactory.\n",
    "\n",
    "RESPONSE:\n",
    "{{{{$lastmessage}}}}\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_reducer = ChatHistoryTruncationReducer(target_count=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat = AgentGroupChat(\n",
    "    agents=[reviewer, copywriter],\n",
    "    selection_strategy=KernelFunctionSelectionStrategy(\n",
    "        initial_agent=reviewer,\n",
    "        function=selection_function,\n",
    "        kernel=kernel,\n",
    "        result_parser=lambda result: str(result.value[0]).strip() if result.value[0] is not None else WRITER_NAME,\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    "    termination_strategy=KernelFunctionTerminationStrategy(\n",
    "        agents=[reviewer],\n",
    "        function=termination_function,\n",
    "        kernel=kernel,\n",
    "        result_parser=lambda result: termination_keyword in str(result.value[0]).lower(),\n",
    "        history_variable_name=\"lastmessage\",\n",
    "        maximum_iterations=10,\n",
    "        history_reducer=history_reducer,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run(user_input: str):\n",
    "    is_complete = False\n",
    "    while not is_complete:\n",
    "        print()\n",
    "\n",
    "        user_input = input(\"User > \").strip()\n",
    "        if not user_input:\n",
    "            continue\n",
    "\n",
    "        if user_input.lower() == \"exit\":\n",
    "            is_complete = True\n",
    "            break\n",
    "\n",
    "        if user_input.lower() == \"reset\":\n",
    "            await chat.reset()\n",
    "            print(\"[Conversation has been reset]\")\n",
    "            continue\n",
    "\n",
    "        # Try to grab files from the script's current directory\n",
    "        if user_input.startswith(\"@\") and len(user_input) > 1:\n",
    "            file_name = user_input[1:]\n",
    "            script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "            file_path = os.path.join(script_dir, file_name)\n",
    "            try:\n",
    "                if not os.path.exists(file_path):\n",
    "                    print(f\"Unable to access file: {file_path}\")\n",
    "                    continue\n",
    "                with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                    user_input = file.read()\n",
    "            except Exception:\n",
    "                print(f\"Unable to access file: {file_path}\")\n",
    "                continue\n",
    "\n",
    "        # Add the current user_input to the chat\n",
    "        await chat.add_chat_message(message=user_input)\n",
    "\n",
    "        try:\n",
    "            async for response in chat.invoke():\n",
    "                if response is None or not response.name:\n",
    "                    continue\n",
    "                print()\n",
    "                print(f\"# {response.name.upper()}:\\n{response.content}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error during chat invocation: {e}\")\n",
    "\n",
    "        # Reset the chat's complete flag for the new conversation round.\n",
    "        chat.is_complete = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_complete = False\n",
    "while not is_complete:\n",
    "    print()\n",
    "\n",
    "    user_input = input(\"User > \").strip()\n",
    "    if not user_input:\n",
    "        continue\n",
    "\n",
    "    if user_input.lower() == \"exit\":\n",
    "        is_complete = True\n",
    "        break\n",
    "\n",
    "    if user_input.lower() == \"reset\":\n",
    "        await chat.reset()\n",
    "        print(\"[Conversation has been reset]\")\n",
    "        continue\n",
    "\n",
    "    # Try to grab files from the script's current directory\n",
    "    if user_input.startswith(\"@\") and len(user_input) > 1:\n",
    "        file_name = user_input[1:]\n",
    "        script_dir = os.path.dirname(os.path.abspath(__file__))\n",
    "        file_path = os.path.join(script_dir, file_name)\n",
    "        try:\n",
    "            if not os.path.exists(file_path):\n",
    "                print(f\"Unable to access file: {file_path}\")\n",
    "                continue\n",
    "            with open(file_path, \"r\", encoding=\"utf-8\") as file:\n",
    "                user_input = file.read()\n",
    "        except Exception:\n",
    "            print(f\"Unable to access file: {file_path}\")\n",
    "            continue\n",
    "\n",
    "    # Add the current user_input to the chat\n",
    "    await chat.add_chat_message(message=user_input)\n",
    "\n",
    "    try:\n",
    "        async for response in chat.invoke():\n",
    "            if response is None or not response.name:\n",
    "                continue\n",
    "            print()\n",
    "            print(f\"# {response.name.upper()}:\\n{response.content}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error during chat invocation: {e}\")\n",
    "\n",
    "    # Reset the chat's complete flag for the new conversation round.\n",
    "    chat.is_complete = False\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
