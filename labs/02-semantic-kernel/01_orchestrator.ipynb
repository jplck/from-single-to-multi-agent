{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d1b588",
   "metadata": {},
   "source": [
    "# Semantic Kernel Orchestrator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e478399a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "# To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings. \n",
    "# Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "base_url=\"https://models.inference.ai.azure.com\"\n",
    "api_key=os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "\n",
    "chat_completion_service = AzureAIInferenceChatCompletion(\n",
    "    ai_model_id=\"gpt-4o\",\n",
    "    api_key=api_key,\n",
    "    endpoint=base_url, # Used to point to your service\n",
    "    service_id=\"azure_openai\", # Optional; for targeting specific services within Semantic Kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999aaa5",
   "metadata": {},
   "source": [
    "You can start using the completion service right away or add the chat completion service to a kernel. You can use the following code to add a service to the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b11cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the chat completion service created above to the kernel\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f44b",
   "metadata": {},
   "source": [
    "Once you've added chat completion services to your kernel, you can retrieve them using the get service method. Below is an example of how you can retrieve a chat completion service from the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "\n",
    "# Retrieve the chat completion service by type\n",
    "chat_completion_service = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Retrieve the chat completion service by id\n",
    "chat_completion_service = kernel.get_service(service_id=\"azure_openai\")\n",
    "\n",
    "# Retrieve the default inference settings\n",
    "execution_settings = kernel.get_prompt_execution_settings_from_service_id(\"azure_openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84e7cf",
   "metadata": {},
   "source": [
    "## Using chat completion service\n",
    "\n",
    "Now that you have a chat completion service, you can use it to generate responses from an AI agent. There are two main ways to use a chat completion service:\n",
    "\n",
    "**Non-streaming**: You wait for the service to generate an entire response before returning it to the user.\n",
    "\n",
    "**Streaming**: Individual chunks of the response are generated and returned to the user as they are created.\n",
    "Before getting started, you will need to manually create an execution settings instance to use the chat completion service if you did not register the service with the kernel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e54ec6",
   "metadata": {},
   "source": [
    "Non-Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fdaf6",
   "metadata": {},
   "source": [
    "Streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d05422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = chat_completion_service.get_streaming_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e2189",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored how to use the Semantic Kernel orchestrator:\n",
    "\n",
    "1. Set up and configured Azure OpenAI chat completion services.\n",
    "2. Integrated chat completion services into a Semantic Kernel instance.\n",
    "3. Demonstrated retrieving and using chat completion services.\n",
    "4. Explored both non-streaming and streaming methods for generating AI responses.\n",
    "\n",
    "Semantic Kernel orchestrators simplify the integration and management of AI services, enabling efficient and flexible AI-driven interactions.\n",
    "\n",
    "For more information, visit the [Semantic Kernel documentation](https://learn.microsoft.com/en-us/semantic-kernel/)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
