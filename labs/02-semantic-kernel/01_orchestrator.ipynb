{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92d1b588",
   "metadata": {},
   "source": [
    "# Semantic Kernel Orchestrator\n",
    "\n",
    "**Goal**: Learn how to orchestrate AI services with Semantic Kernel.\n",
    "\n",
    "## What You'll Build\n",
    "- Initialize a Semantic Kernel with Azure OpenAI or GitHub Models\n",
    "- Create and configure AI services\n",
    "- Set up the foundation for agent orchestration\n",
    "\n",
    "‚è±Ô∏è **Time**: ~10 minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568c9323",
   "metadata": {},
   "source": [
    "## üöÄ Quick Setup\n",
    "\n",
    "Install required packages and configure environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e478399a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using Azure OpenAI\n"
     ]
    }
   ],
   "source": [
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "import os\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "service_id = \"azure_openai\"\n",
    "\n",
    "if os.environ.get(\"AZURE_OPENAI_API_KEY\"):\n",
    "    print(\"Using Azure OpenAI\")\n",
    "    chat_completion_service = AzureChatCompletion(\n",
    "        deployment_name=os.environ[\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"],  \n",
    "        api_key=os.environ[\"AZURE_OPENAI_API_KEY\"],\n",
    "        endpoint=os.environ[\"AZURE_OPENAI_ENDPOINT\"],\n",
    "        service_id=service_id,\n",
    "    )\n",
    "else:\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings. \n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    base_url=\"https://models.inference.ai.azure.com\"\n",
    "    api_key=os.environ[\"GITHUB_TOKEN\"]\n",
    "\n",
    "    chat_completion_service = AzureAIInferenceChatCompletion(\n",
    "        ai_model_id=\"gpt-4o-mini\",\n",
    "        api_key=api_key,\n",
    "        endpoint=base_url,\n",
    "        service_id=service_id,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3999aaa5",
   "metadata": {},
   "source": [
    "## ‚öôÔ∏è Configure AI Service\n",
    "\n",
    "Create your Semantic Kernel and connect to Azure OpenAI:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1b11cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel import Kernel\n",
    "\n",
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the chat completion service created above to the kernel\n",
    "kernel.add_service(chat_completion_service)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d06f44b",
   "metadata": {},
   "source": [
    "## üß† Create Your Kernel\n",
    "\n",
    "Initialize the Semantic Kernel - your AI orchestration engine:\n",
    "\n",
    "Once you've added chat completion services to your kernel, you can retrieve them using the get service method. Below is an example of how you can retrieve a chat completion service from the kernel."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3173f972",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.connectors.ai.chat_completion_client_base import ChatCompletionClientBase\n",
    "\n",
    "# Retrieve the chat completion service by type\n",
    "chat_completion_service = kernel.get_service(type=ChatCompletionClientBase)\n",
    "\n",
    "# Retrieve the chat completion service by id\n",
    "chat_completion_service = kernel.get_service(service_id=\"azure_openai\")\n",
    "\n",
    "# Retrieve the default inference settings\n",
    "execution_settings = kernel.get_prompt_execution_settings_from_service_id(\"azure_openai\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e84e7cf",
   "metadata": {},
   "source": [
    "## Using chat completion service\n",
    "\n",
    "Now that you have a chat completion service, you can use it to generate responses from an AI agent. There are two main ways to use a chat completion service:\n",
    "\n",
    "**Non-streaming**: You wait for the service to generate an entire response before returning it to the user.\n",
    "\n",
    "**Streaming**: Individual chunks of the response are generated and returned to the user as they are created.\n",
    "Before getting started, you will need to manually create an execution settings instance to use the chat completion service if you did not register the service with the kernel\n",
    "\n",
    "## üéØ Test Your Setup\n",
    "\n",
    "Let's verify everything works by asking the AI a simple question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e54ec6",
   "metadata": {},
   "source": [
    "## üí¨ Non-Streaming Chat with Your AI\n",
    "\n",
    "Now let's have a conversation with our AI service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1502508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2fdaf6",
   "metadata": {},
   "source": [
    "## üîß Streaming Chat with your AI:\n",
    "\n",
    "Try customizing the AI's behavior with specific prompts:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d05422",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "\n",
    "chat_history = ChatHistory()\n",
    "chat_history.add_user_message(\"Hello, how are you?\")\n",
    "\n",
    "response = chat_completion_service.get_streaming_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "async for chunk in response:\n",
    "    print(chunk, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6e2189",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "In this notebook, we've explored how to use the Semantic Kernel orchestrator:\n",
    "\n",
    "1. Set up and configured Azure OpenAI chat completion services.\n",
    "2. Integrated chat completion services into a Semantic Kernel instance.\n",
    "3. Demonstrated retrieving and using chat completion services.\n",
    "4. Explored both non-streaming and streaming methods for generating AI responses.\n",
    "\n",
    "Semantic Kernel orchestrators simplify the integration and management of AI services, enabling efficient and flexible AI-driven interactions.\n",
    "\n",
    "For more information, visit the [Semantic Kernel documentation](https://learn.microsoft.com/en-us/semantic-kernel/).\n",
    "\n",
    "## ‚úÖ What You've Accomplished\n",
    "\n",
    "üéâ **Great job!** You've successfully:\n",
    "- Set up Semantic Kernel with Azure OpenAI\n",
    "- Created your first AI orchestration foundation\n",
    "- Tested basic chat functionality\n",
    "\n",
    "## üöÄ Next Steps\n",
    "Ready to level up? Check out:\n",
    "- **02_functions.ipynb** - Add tools and functions to your agents\n",
    "- **03_multi-modal.ipynb** - Work with images and other media\n",
    "\n",
    "**Pro Tip**: The kernel you created here is the foundation for all multi-agent scenarios!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
