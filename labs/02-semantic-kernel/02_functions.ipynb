{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecff1399",
   "metadata": {},
   "source": [
    "# Function Calling\n",
    "\n",
    "The most powerful feature of chat completion is the ability to call functions from the model. This allows you to create a chat bot that can interact with your existing code, making it possible to automate business processes, create code snippets, and more.\n",
    "With Semantic Kernel, we simplify the process of using function calling by automatically describing your functions and their parameters to the model and then handling the back-and-forth communication between the model and your code.\n",
    "When using function calling, however, it's good to understand what's actually happening behind the scenes so that you can optimize your code and make the most of this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09d2f8d9",
   "metadata": {},
   "source": [
    "## How auto function calling works\n",
    "\n",
    "When you call a function from the model, the model generates a JSON object that describes the function and its parameters. This JSON object is then passed to your code, which can then execute the function with the provided parameters.\n",
    "The model is able to generate this JSON object because it has been trained on a large dataset of code and natural language, allowing it to understand the structure of functions and their parameters.\n",
    "The model also has a built-in understanding of the types of parameters that functions can take, which allows it to generate the correct JSON object for the function being called.\n",
    "The model uses a combination of natural language processing and code generation techniques to create the JSON object, which is then passed to your code for execution.\n",
    "\n",
    "When you make a request to a model with function calling enabled, Semantic Kernel performs the following steps:\n",
    "\n",
    "![FunctionCallingProcessSk](../../assets/images/functioncalling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1f72df",
   "metadata": {},
   "source": [
    "## Setting Up the Environment\n",
    "\n",
    "First, let's import the necessary libraries and set up our environment. We'll use Semantic Kernel's Azure OpenAI connector to work with the OpenAI models that support function calling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb87f62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureChatCompletion,\n",
    "    AzureChatPromptExecutionSettings\n",
    ")\n",
    "\n",
    "from semantic_kernel.functions import kernel_function, KernelArguments\n",
    "from semantic_kernel.contents.chat_history import ChatHistory\n",
    "from semantic_kernel.connectors.ai.function_choice_behavior import FunctionChoiceBehavior\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "chat_completion_service = AzureChatCompletion(\n",
    "            service_id=\"azure_openai\",\n",
    "            deployment_name=os.environ.get(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "            api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "            endpoint=os.environ.get(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "            api_version=os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f83a8aa7",
   "metadata": {},
   "source": [
    "At a high-level, a plugin is a group of functions that can be exposed to AI apps and services. The functions within plugins can then be orchestrated by an AI application to accomplish user requests. Within Semantic Kernel, you can invoke these functions automatically with function calling.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16bd2d59",
   "metadata": {},
   "source": [
    "## Creating a Plugin with Functions\n",
    "\n",
    "Let's create a Weather plugin that includes two functions: one to get current weather data and another to get a weather forecast. In a real implementation, these functions would call external APIs, but for demonstration purposes, we'll return mock data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bd3e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a plugin with functions to get weather data and forecast\n",
    "class WeatherPlugin:\n",
    "    \"\"\"\n",
    "    A plugin to get weather data and forecast\n",
    "    \"\"\"\n",
    "    # Define functions for function calling\n",
    "    @kernel_function(name=\"get_weather_data\", description=\"Get weather data for a specific location\")\n",
    "    async def get_weather_data(self, location: str) -> str:\n",
    "        \"\"\"\n",
    "        Stub function to get weather data for a specific location\n",
    "        In a real implementation, this would call a weather API\n",
    "        \"\"\"\n",
    "        print(f\"Getting weather data for {location}\")\n",
    "        weather_data = {\n",
    "            \"temperature\": 25,  # Celsius\n",
    "            \"cloud_cover\": 0.2,  # 20%\n",
    "            \"irradiance\": 800,  # W/m²\n",
    "            \"precipitation_chance\": 0.1,  # 10%\n",
    "        }\n",
    "        return json.dumps(weather_data)\n",
    "\n",
    "    @kernel_function(name=\"get_weather_forecast\", description=\"Get weather forecast for a specific location for the next day\")\n",
    "    async def get_weather_forecast(self, location: str) -> str:\n",
    "        \"\"\"\n",
    "        Stub function to get weather forecast for a specific location\n",
    "        In a real implementation, this would call a weather API\n",
    "        \"\"\"\n",
    "        print(f\"Getting weather forecast for {location}\")\n",
    "        forecast_data = {\n",
    "            \"temperature\": 28,  # Celsius\n",
    "            \"cloud_cover\": 0.1,  # 10%\n",
    "            \"irradiance\": 900,  # W/m²\n",
    "            \"precipitation_chance\": 0.05,  # 5%\n",
    "        }\n",
    "        return json.dumps(forecast_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ddf542",
   "metadata": {},
   "source": [
    "## Setting Up the Kernel\n",
    "\n",
    "Now, let's set up the Semantic Kernel and add our chat completion service and weather plugin. The kernel serves as the central orchestrator for our application."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1dc6e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the kernel\n",
    "kernel = Kernel()\n",
    "\n",
    "# Add the chat completion service created above to the kernel\n",
    "kernel.add_service(chat_completion_service)\n",
    "\n",
    "# Add the weather plugin to the kernel\n",
    "# The plugin is a group of functions that can be exposed to AI apps and services\n",
    "kernel.add_plugin(WeatherPlugin(), plugin_name=\"weather_plugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d77918",
   "metadata": {},
   "source": [
    "## Testing Function Calling\n",
    "\n",
    "Now let's test our function calling capabilities. We'll create a chat history, add a user message asking about the weather, and then use our chat completion service with auto function calling enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9aaf70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the chat history\n",
    "chat_history = ChatHistory()\n",
    "\n",
    "user_input = \"What is the weather like in Seattle?\"\n",
    "system_input = \"You are a helpful assistant that provides weather information. Keep it short and concise.\"\n",
    "chat_history.add_user_message(user_input)\n",
    "\n",
    "execution_settings = AzureChatPromptExecutionSettings()\n",
    "execution_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    kernel=kernel,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(f\"Assistant: {response}\")\n",
    "\n",
    "# Add the assistant's response to the chat history\n",
    "chat_history.add_assistant_message(response.content)\n",
    "\n",
    "chat_history.add_user_message(\"What is the weather like in Seattle tomorrow?\")\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    kernel=kernel,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "print(f\"Assistant: {response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc6bbf36",
   "metadata": {},
   "source": [
    "## Creating More Complex Functions\n",
    "\n",
    "Now let's create some additional functions that are more complex and demonstrate how they can be used together in a real-world scenario."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318bb6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WeatherAnalysisPlugin:\n",
    "    \"\"\"\n",
    "    A plugin to analyze weather data and provide recommendations\n",
    "    \"\"\"\n",
    "    @kernel_function(name=\"analyze_weather_impact\", description=\"Analyze how weather will impact outdoor activities\")\n",
    "    async def analyze_weather_impact(self, weather_data: str, activity_type: str) -> str:\n",
    "        \"\"\"\n",
    "        Analyze weather data and provide recommendations for outdoor activities\n",
    "        Args:\n",
    "            weather_data: JSON string containing weather information\n",
    "            activity_type: Type of activity (hiking, picnic, sports, etc.)\n",
    "        \"\"\"\n",
    "        print(f\"Analyzing weather impact for {activity_type}\")\n",
    "        # In a real implementation, this would analyze the weather data and return recommendations\n",
    "        weather = json.loads(weather_data)\n",
    "        \n",
    "        analysis = {\n",
    "            \"activity\": activity_type,\n",
    "            \"suitable\": weather[\"temperature\"] > 20 and weather[\"precipitation_chance\"] < 0.3,\n",
    "            \"recommendations\": [],\n",
    "        }\n",
    "        \n",
    "        if weather[\"temperature\"] > 30:\n",
    "            analysis[\"recommendations\"].append(\"Bring plenty of water due to high temperature\")\n",
    "        if weather[\"cloud_cover\"] < 0.3:\n",
    "            analysis[\"recommendations\"].append(\"Bring sunscreen as UV exposure will be high\")\n",
    "        if weather[\"precipitation_chance\"] > 0.1:\n",
    "            analysis[\"recommendations\"].append(\"Consider bringing rain gear just in case\")\n",
    "            \n",
    "        return json.dumps(analysis)\n",
    "\n",
    "# Add the new plugin to the kernel\n",
    "kernel.add_plugin(WeatherAnalysisPlugin(), plugin_name=\"weather_analysis_plugin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489a7e88",
   "metadata": {},
   "source": [
    "## Testing Complex Function Interactions\n",
    "\n",
    "Let's test how the model can chain multiple function calls together to respond to a more complex question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37bff03b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new chat history for complex interaction\n",
    "complex_chat = ChatHistory()\n",
    "\n",
    "# Ask a more complex question that requires multiple function calls\n",
    "complex_chat.add_user_message(\"I'm planning a hiking trip in Seattle tomorrow. Is the weather going to be good for hiking?\")\n",
    "\n",
    "# Use the same execution settings with auto function calling\n",
    "complex_response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=complex_chat,\n",
    "    kernel=kernel,\n",
    "    settings=execution_settings,\n",
    ")\n",
    "\n",
    "print(f\"Assistant: {complex_response}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ccd6e7",
   "metadata": {},
   "source": [
    "## Understanding Function Calling in the Background\n",
    "\n",
    "Let's examine what's happening in the background during function calling. We'll set up a special execution setting that lets us see the actual function calls being made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2672444e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a chat history to observe function calls\n",
    "observation_chat = ChatHistory()\n",
    "observation_chat.add_user_message(\"What's the temperature in Paris right now, and will it be good for a picnic tomorrow?\")\n",
    "\n",
    "# Create execution settings with debug info\n",
    "debug_settings = AzureChatPromptExecutionSettings()\n",
    "debug_settings.function_choice_behavior = FunctionChoiceBehavior.Auto()\n",
    "debug_settings.extension_data = {\"include_raw_responses\": True}  # This depends on the specific implementation\n",
    "\n",
    "# Get response with debug information\n",
    "debug_response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=observation_chat,\n",
    "    kernel=kernel,\n",
    "    settings=debug_settings,\n",
    ")\n",
    "\n",
    "# Print the debug information if available\n",
    "if hasattr(debug_response, 'metadata') and debug_response.metadata:\n",
    "    print(\"Function calling metadata:\")\n",
    "    print(debug_response.metadata)\n",
    "    \n",
    "print(f\"\\nFinal response: {debug_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0103a79",
   "metadata": {},
   "source": [
    "## Optional Exercise: Creating Your Own Plugin and Testing Function Calling\n",
    "\n",
    "Now it's your turn! Create a new plugin that provides useful functions for a specific domain of your choice. Then test how the model uses these functions in response to user queries.\n",
    "\n",
    "Here's a template to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82cc8388",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create your own plugin\n",
    "class MyCustomPlugin:\n",
    "    \"\"\"\n",
    "    Description of your custom plugin\n",
    "    \"\"\"\n",
    "    @kernel_function(name=\"my_function1\", description=\"Description of what this function does\")\n",
    "    async def my_function1(self, param1: str, param2: str = \"default\") -> str:\n",
    "        \"\"\"\n",
    "        Detailed description of what this function does\n",
    "        \n",
    "        Args:\n",
    "            param1: Description of param1\n",
    "            param2: Description of param2\n",
    "        \"\"\"\n",
    "        # Your function implementation here\n",
    "        print(f\"Function called with {param1} and {param2}\")\n",
    "        return json.dumps({\"result\": f\"Processed {param1} with {param2}\"})\n",
    "    \n",
    "    @kernel_function(name=\"my_function2\", description=\"Description of what this function does\")\n",
    "    async def my_function2(self, input_data: str) -> str:\n",
    "        \"\"\"Another function implementation\"\"\"\n",
    "        # Your function implementation here\n",
    "        return f\"Result: {input_data}\"\n",
    "\n",
    "# Add your plugin to the kernel\n",
    "# kernel.add_plugin(MyCustomPlugin(), plugin_name=\"my_custom_plugin\")\n",
    "\n",
    "# Test your plugin with a user query\n",
    "# my_chat = ChatHistory()\n",
    "# my_chat.add_user_message(\"A query that would trigger your custom functions\")\n",
    "# \n",
    "# my_response = await chat_completion_service.get_chat_message_content(\n",
    "#     chat_history=my_chat,\n",
    "#     kernel=kernel,\n",
    "#     settings=execution_settings,\n",
    "# )\n",
    "# \n",
    "# print(f\"Response: {my_response.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5945b926",
   "metadata": {},
   "source": [
    "## Advanced Challenge: Multi-Function Conversation Agent\n",
    "\n",
    "Now that you understand how function calling works, here's a more advanced challenge:\n",
    "\n",
    "Create a full-featured conversational agent that can:\n",
    "\n",
    "1. Use multiple functions from different plugins to answer complex queries\n",
    "2. Maintain conversation context across multiple turns\n",
    "3. Handle errors gracefully if a function call fails\n",
    "4. Provide helpful responses that synthesize information from multiple function calls\n",
    "\n",
    "Example implementation areas:\n",
    "- A travel assistant that checks weather, flight status, and hotel availability\n",
    "- A personal finance assistant that can check balances, analyze spending, and suggest budgets\n",
    "- A health and wellness assistant that tracks activity, suggests workouts, and monitors nutrition\n",
    "\n",
    "Bonus points if you implement:\n",
    "- Function call tracing/logging\n",
    "- User authentication for sensitive functions\n",
    "- Fallback mechanisms when functions aren't available\n",
    "\n",
    "Happy coding!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
