{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd8e169e",
   "metadata": {},
   "source": [
    "# Using images with chat completion\n",
    "\n",
    "The Semantic Kernel chat completion connectors support passing both images and text at the same time to a chat completion AI model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fa85293",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import json\n",
    "import asyncio\n",
    "from typing import Dict, Any\n",
    "\n",
    "from semantic_kernel import Kernel\n",
    "from semantic_kernel.connectors.ai.azure_ai_inference import AzureAIInferenceChatCompletion\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatPromptExecutionSettings\n",
    "\n",
    "from semantic_kernel.contents import ChatHistory, ChatMessageContent, ImageContent, TextContent\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings. \n",
    "# Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "base_url=\"https://models.inference.ai.azure.com\"\n",
    "api_key=os.environ[\"GITHUB_TOKEN\"]\n",
    "model=\"gpt-4o\"\n",
    "\n",
    "chat_completion_service = AzureAIInferenceChatCompletion(\n",
    "    ai_model_id=model,\n",
    "    api_key=api_key,\n",
    "    endpoint=base_url, # Used to point to your service\n",
    "    service_id=\"azure_openai\", # Optional; for targeting specific services within Semantic Kernel\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7d3a601",
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_history = ChatHistory()\n",
    "    \n",
    "user_input = \"Your job is describing images.\"\n",
    "chat_history.add_user_message(user_input)\n",
    "\n",
    "# If you have an image that is accessible via a URI, you can use the following code.\n",
    "#chat_history.add_message(\n",
    "#     ChatMessageContent(\n",
    "#         role=\"user\",\n",
    "#         items=[\n",
    "#             TextContent(text=\"What’s in this image?\"),\n",
    "#             ImageContent(uri=uri),\n",
    "#         ]\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# If you have an image that is accessible via a local file path, you can use the following code.\n",
    "chat_history.add_message(\n",
    "    ChatMessageContent(\n",
    "        role=\"user\",\n",
    "        items=[\n",
    "            TextContent(text=\"What’s in this image?\"),\n",
    "            ImageContent.from_image_file(path=\"../../labs/02-semantic-kernel/R.jpeg\"),\n",
    "        ]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Invoke the chat completion model.\n",
    "response = await chat_completion_service.get_chat_message_content(\n",
    "    chat_history=chat_history,\n",
    "    settings=AzureChatPromptExecutionSettings(\n",
    "        temperature=0.5,\n",
    "        max_tokens=1000,\n",
    "        top_p=1.0,\n",
    "        frequency_penalty=0.0,\n",
    "        presence_penalty=0.0\n",
    "    )\n",
    ")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51c56b0e",
   "metadata": {},
   "source": [
    "# Conlusion\n",
    "The Semantic Kernel chat completion connectors support passing both images and text at the same time to a chat completion AI model. This allows for more complex interactions and can be useful in scenarios where visual context is important.\n",
    "The chat completion connector can be used to send images to the model, which can then analyze the image and provide a response based on its content. This can be useful in scenarios where visual context is important, such as in customer support or creative applications."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
