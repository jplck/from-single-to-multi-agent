{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "94d3e793",
   "metadata": {},
   "source": [
    "# Advanced Multi-Agent Reasoning with AutoGen\n",
    "\n",
    "In this notebook, we'll explore how to build multi-agent systems with enhanced reasoning capabilities using AutoGen. We'll extend the concepts from previous notebooks by adding a dedicated reasoning agent that can evaluate conversations and improve outcomes.\n",
    "\n",
    "## What is Reasoning in Multi-Agent Systems?\n",
    "\n",
    "Reasoning in multi-agent systems involves:\n",
    "- Evaluating the quality and consistency of agent interactions\n",
    "- Identifying contradictions or logical errors in conversations\n",
    "- Providing meta-feedback to improve the overall system performance\n",
    "- Using specialized models (like o1-mini) that excel at logical reasoning tasks\n",
    "\n",
    "Let's start by setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c70dfdea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages if needed\n",
    "# !pip install autogen-agentchat autogen-ext python-dotenv pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cecf214b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import asyncio\n",
    "import os\n",
    "import pytz\n",
    "from datetime import datetime\n",
    "from autogen_agentchat.agents import AssistantAgent\n",
    "from autogen_agentchat.teams import MagenticOneGroupChat\n",
    "from autogen_agentchat.messages import TextMessage\n",
    "from autogen_agentchat.teams._group_chat._magentic_one._magentic_one_orchestrator import MagenticOneOrchestrator\n",
    "from autogen_agentchat.conditions import TextMentionTermination, MaxMessageTermination\n",
    "from autogen_agentchat.ui import Console\n",
    "from autogen_ext.models.openai import OpenAIChatCompletionClient, AzureOpenAIChatCompletionClient\n",
    "from autogen_core import CancellationToken\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef625f35",
   "metadata": {},
   "source": [
    "## 1. Setting Up Azure OpenAI with Multiple Models\n",
    "\n",
    "For advanced reasoning, we'll use multiple LLM models - a standard model for general tasks and a specialized reasoning model (o1-mini) optimized for logical reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072917aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.environ.get(\"GITHUB_TOKEN\") is None:\n",
    "    model_client = AzureOpenAIChatCompletionClient(\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        model=os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "        model_info={\n",
    "            \"json_output\": True,\n",
    "            \"function_calling\": True,\n",
    "            \"vision\": False,\n",
    "            \"family\": \"unknown\",\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Update this to o1 model when available\n",
    "    o1_model_client = AzureOpenAIChatCompletionClient(\n",
    "        azure_deployment=os.getenv(\"AZURE_OPENAI_COMPLETION_DEPLOYMENT_NAME\"),\n",
    "        model=os.getenv(\"AZURE_OPENAI_COMPLETION_MODEL\"),\n",
    "        api_version=os.getenv(\"AZURE_OPENAI_API_VERSION\"),\n",
    "        azure_endpoint=os.getenv(\"AZURE_OPENAI_ENDPOINT\"),\n",
    "        api_key=os.environ.get(\"AZURE_OPENAI_API_KEY\"),\n",
    "        model_info={\n",
    "            \"json_output\": True,\n",
    "            \"function_calling\": True,\n",
    "            \"vision\": False,\n",
    "            \"family\": \"unknown\",\n",
    "        },\n",
    "    )\n",
    "else:\n",
    "    # To authenticate with the model you will need to generate a personal access token (PAT) in your GitHub settings. \n",
    "    # Create your PAT token by following instructions here: https://docs.github.com/en/authentication/keeping-your-account-and-data-secure/managing-your-personal-access-tokens\n",
    "    token = os.environ[\"GITHUB_TOKEN\"]\n",
    "    endpoint = \"https://models.inference.ai.azure.com\"\n",
    "\n",
    "    # Standard model for general tasks\n",
    "    model_client = OpenAIChatCompletionClient(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        base_url=endpoint,\n",
    "        api_key=token\n",
    "    )\n",
    "\n",
    "    # Specialized model for reasoning tasks\n",
    "    o1_model_client = OpenAIChatCompletionClient(\n",
    "        model=\"o1-mini\",\n",
    "        base_url=endpoint,\n",
    "        api_key=token\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365564f2",
   "metadata": {},
   "source": [
    "## 2. Creating a Dedicated Reasoning Agent\n",
    "\n",
    "We'll create a dedicated reasoning agent that can analyze conversations for inconsistencies, open questions, and contradictions. This agent uses the o1-mini model, which is specifically designed for logical reasoning tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f05a8ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a reasoning agent with the o1-mini model\n",
    "reasoning_agent = AssistantAgent(\n",
    "    name=\"reasoning_agent\", \n",
    "    model_client=o1_model_client, \n",
    "    system_message=None,\n",
    "    description=\"A helpful assistant that can check the quality of the conversation and provide feedback to the agents. The checker agent can provide feedback on the quality of the conversation, the relevance of the responses, and the overall satisfaction of the user. The checker agent can also provide suggestions for improvement to the agents and should be consulted before completing the last task.\",\n",
    "    tools=None\n",
    ")\n",
    "\n",
    "# Define a conversation checking tool that uses the reasoning agent\n",
    "async def check_conversation(messages: str) -> str:\n",
    "    print(\"executing check_conversation\")\n",
    "    response = await reasoning_agent.on_messages(\n",
    "                [TextMessage(content=f\"Check the following messages for inconsistencies, open questions and contradictions and give concrete feedback. Here are some facts that might help: Dennis lives in somewhere in Germany. Messages: {messages}\", source=\"user\")], CancellationToken()\n",
    "                )\n",
    "    print(response)\n",
    "    return f\"This is my feedback {response}.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f8fe6fe",
   "metadata": {},
   "source": [
    "## 3. Creating Domain-Specific Tools\n",
    "\n",
    "Now let's define various tools that our specialized agents will use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d1e93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define tools for our agents\n",
    "async def get_weather(city: str) -> str:\n",
    "    print(\"executing get_weather\")\n",
    "    return f\"The weather in {city} is 73 degrees and Sunny.\"\n",
    "\n",
    "async def get_medical_history(username: str) -> str:\n",
    "    \"\"\"Get the medical history for a given username with known allergies and food restrictions.\"\"\"\n",
    "    print(\"executing get_medical_history\")\n",
    "    return f\"{username} has an allergy to peanuts and eggs.\"\n",
    "\n",
    "async def get_available_incredients(location: str) -> str:\n",
    "    \"\"\"Get the available incredients for a given location.\"\"\"\n",
    "    print(\"executing get_available_incredients\")\n",
    "    return f\"Available incredients in {location} are: eggs, milk, bread, peanuts, beer, wine, salmon, spinache, oil and butter.\"\n",
    "\n",
    "def get_current_username(input: str) -> str:\n",
    "    \"\"\"Get the username of the current user.\"\"\"\n",
    "    print(\"executing get_current_username\")\n",
    "    return \"Dennis\"\n",
    "\n",
    "def get_current_location_of_user(username: str) -> str:\n",
    "    \"\"\"Get the current timezone location of the user for a given username.\"\"\"\n",
    "    print(\"executing get_current_location\")\n",
    "    print(username)\n",
    "    if \"Dennis\" in username:\n",
    "        return \"Europe/Berlin\"\n",
    "    else:\n",
    "        return \"America/New_York\"\n",
    "\n",
    "def get_current_time(location: str) -> str:\n",
    "    \"\"\"Get the current time in the given location. The pytz is used to get the timezone for that location. Location names should be in a format like America/Seattle, Asia/Bangkok, Europe/London. Anything in Germany should be Europe/Berlin\"\"\"\n",
    "    try:\n",
    "        print(\"get current time for location: \", location)\n",
    "        timezone = pytz.timezone(location)\n",
    "        # Get the current time in the timezone\n",
    "        now = datetime.now(timezone)\n",
    "        current_time = now.strftime(\"%I:%M:%S %p\")\n",
    "        return current_time\n",
    "    except Exception as e:\n",
    "        print(\"Error: \", e)\n",
    "        return \"Sorry, I couldn't find the timezone for that location.\"\n",
    "\n",
    "# Test one of our tools\n",
    "await get_weather(\"Berlin\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a6761f",
   "metadata": {},
   "source": [
    "## 4. Creating Specialized Agents\n",
    "\n",
    "Now we'll create specialized agents, each with specific tools and responsibilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4862f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# User information agent\n",
    "users_agent = AssistantAgent(\n",
    "    \"users_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_current_username, get_medical_history],\n",
    "    description=\"A helpful assistant that can knows things about the user like the username.\",\n",
    "    system_message=\"You are a helpful assistant that can retrieve the username of the current user.\",\n",
    ")\n",
    "\n",
    "# Location agent\n",
    "location_agent = AssistantAgent(\n",
    "    \"location_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_current_location_of_user],\n",
    "    description=\"A assistant that can find the physical location of a user.\",\n",
    "    system_message=\"You are a helpful assistant that can suggest details for a location and can utilize any context information provided.\",\n",
    ")\n",
    "\n",
    "# Time agent\n",
    "time_agent = AssistantAgent(\n",
    "    \"time_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_current_time],\n",
    "    description=\"A helpful assistant that knows time in a specific location.\",\n",
    "    system_message=\"You are a helpful assistant that can retrieve the current time for a given location.\",\n",
    ")\n",
    "\n",
    "# Chef agent\n",
    "chef_agent = AssistantAgent(\n",
    "    \"chef_agent\",\n",
    "    model_client=model_client,\n",
    "    tools=[get_available_incredients],\n",
    "    description=\"A helpful assistant that can suggest meals and dishes for the right time of the day, location, available ingredients, user preferences and allergies.\",\n",
    "    system_message=\"You are a helpful assistant that can recommend dishes for the right time of the day, location, available ingredients and user preferences. Make sure you ask for individual food preferences and allergies as input.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ed62991",
   "metadata": {},
   "source": [
    "## 5. Creating Synthesis and Consultation Agents\n",
    "\n",
    "In addition to our specialized agents, we need agents that can synthesize information and provide feedback:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8ae830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary agent for synthesizing information - not used in chat\n",
    "summary_agent = AssistantAgent(\n",
    "    \"summary_agent\",\n",
    "    model_client=model_client,\n",
    "    description=\"A helpful assistant that can summarize details about conversations.\",\n",
    "    system_message=\"You are a helpful assistant that can take in all of the suggestions and advice from the other agents and leverage them to answer questions. You must ensure that you use that the other agents can solve the problem. When all open questions have been answered, you can respond with TERMINATE.\",\n",
    ")\n",
    "\n",
    "# Consultation agent for checking conversation quality\n",
    "consultation_agent = AssistantAgent(\n",
    "    name=\"consultation_agent\", \n",
    "    model_client=model_client, \n",
    "    system_message=\"Your task is to check the complete message flow for inconsistencies, open questions and contradictions and give concrete feedback. You should also provide suggestions for improvement to the agents and should be consulted before completing the last task.\",\n",
    "    description=\"A helpful assistant that can check the quality of the conversation and provide feedback to the agents. The checker agent can provide feedback on the quality of the conversation, the relevance of the responses, and the overall satisfaction of the user. The checker agent can also provide suggestions for improvement to the agents and should be consulted before completing the last task.\",\n",
    "    tools=[check_conversation]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9dd4b",
   "metadata": {},
   "source": [
    "## 6. Running a Multi-Agent System with Reasoning\n",
    "\n",
    "Now we'll run our multi-agent system with the reasoning capability integrated:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acde0c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_reasoning_multi_agent():\n",
    "    # Set a message limit to prevent infinite conversations\n",
    "    inner_termination = MaxMessageTermination(20)\n",
    "    \n",
    "    # Create a MagenticOne group chat with our agents\n",
    "    magenticteam = MagenticOneGroupChat(\n",
    "        [users_agent, location_agent, time_agent, chef_agent, consultation_agent], \n",
    "        model_client=model_client, \n",
    "        termination_condition=inner_termination\n",
    "    )\n",
    "\n",
    "    # Run the team and stream messages to the console\n",
    "    stream = magenticteam.run_stream(task=\"I want to have something to eat. What would you recommend?\")\n",
    "    await Console(stream)\n",
    "\n",
    "# Run our multi-agent system\n",
    "await run_reasoning_multi_agent()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281cdf8",
   "metadata": {},
   "source": [
    "## 7. Understanding the Role of the Reasoning Agent\n",
    "\n",
    "The reasoning agent plays a critical role in our multi-agent system by:\n",
    "\n",
    "1. **Consistency Checking**: Identifying contradictions in the conversation.\n",
    "2. **Gap Detection**: Finding unanswered questions or missing information.\n",
    "3. **Logical Analysis**: Ensuring that conclusions follow logically from premises.\n",
    "4. **Quality Improvement**: Providing feedback to other agents to improve their responses.\n",
    "\n",
    "The o1-mini model is particularly well-suited for this task as it's designed for logical reasoning and analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca2b63f",
   "metadata": {},
   "source": [
    "## 8. Expanding the System - Exercise\n",
    "\n",
    "Try modifying the system to enhance its reasoning capabilities:\n",
    "\n",
    "1. Add a fact-checking agent that verifies statements made by other agents.\n",
    "2. Implement a planning agent that can structure the conversation to reach goals more efficiently.\n",
    "3. Create a contradiction resolution mechanism when the reasoning agent identifies logical inconsistencies.\n",
    "\n",
    "Here's a template to get you started:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c4e329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a fact-checking agent\n",
    "# fact_checking_agent = AssistantAgent(\n",
    "#     \"fact_checker\",\n",
    "#     model_client=o1_model_client,  # Using the reasoning-focused model\n",
    "#     description=\"An agent that verifies factual claims made during the conversation.\",\n",
    "#     system_message=\"You are responsible for checking factual claims made by other agents. When you spot a claim that needs verification, research it and provide accurate information.\",\n",
    "# )\n",
    "\n",
    "# Define a function to analyze contradictions\n",
    "# async def resolve_contradiction(claim1: str, claim2: str) -> str:\n",
    "#     \"\"\"Analyzes two contradicting claims and attempts to resolve the contradiction.\"\"\"\n",
    "#     # Your implementation here\n",
    "#     return \"Resolution explanation\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf40cea7",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we've explored how to enhance multi-agent systems with advanced reasoning capabilities:\n",
    "\n",
    "1. We created a dedicated reasoning agent using a specialized model (o1-mini).\n",
    "2. We implemented a consultation mechanism to check conversation quality.\n",
    "3. We integrated this reasoning capability into a collaborative multi-agent system.\n",
    "4. We explored how reasoning enhances the overall performance of agent conversations.\n",
    "\n",
    "By adding meta-cognitive abilities to our multi-agent systems, we can create more robust, accurate, and logically sound AI assistants capable of handling complex tasks while maintaining internal consistency.\n",
    "\n",
    "For more advanced applications, consider:\n",
    "- Incorporating multiple reasoning agents with different specialties\n",
    "- Adding formal logic verification\n",
    "- Implementing self-correction mechanisms based on reasoning feedback\n",
    "\n",
    "These techniques help move AI systems from simple pattern matching to more sophisticated reasoning-based intelligence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
